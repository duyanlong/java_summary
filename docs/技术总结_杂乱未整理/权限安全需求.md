存储安全：
高难 技术业务管理拆分：两段密码，三套集群来解决不同安全方案的业务线场景，画出架构图  金平协助整理  保留技术管理域由两段密码控制；hive有ranger管理、clickhouse配置文件+SQL授权语法实现，另外需要考虑项目账号库的授权管理验证
ranger貌似可以控制hadoop账号读取HIVE和HDFS上的数据，admin账号可以通过两段密码限制登录权限
clickhouse可将default用户使用两段密码登录，之后在命令行创建用户分配权限
ranger的加密是否可应用到hdfs文件和hive查询
ranger控制不了spark sql的查询
hive grant、revoke方式管控可以控制到spark sql待验证
hdfs web页面下载数据文件功能关闭？ or 限制？
clickhouse解密数据流程

高 加密：AES-UDF，需测试千万级别的性能  陈勇设计测试用例、李东城测试，自带有aes_en**函数  https://cwiki.apache.org/confluence/display
/Hive/LanguageManual+UDF
中 用非textfile，做数据加密；不能下载，服务器不装工具
低 销毁：通过定时任务销毁
低 脱敏：可视化展示时进行脱敏展示

操作安全：
高难 传输元数据加密，数据计算和数据传输  给时间表，请教剑明、相爷、俊达   10.28  方案设计，参考相爷go lang密码接口
高 中台系统操作跟踪：datax异常日志中敏感信息加密或去除？or 隐藏？  李胜步 or 李东城
中 原生操作日志：原生的Clickhouse等日志比较分散，需集中接入日志中心
中 系统操作记录接入日志中心

网络安全：
高 中台服务器访问安全：堡垒机+跳板机，提供专用堡垒机，不需要跳板机，EMR服务器账号由运维建  林秋+余勇+映柳
低 jdbc传输加密，jdbc协议证书  ssl

|安全所属模块|安全项|验证内容|验证人|验证结果|输出物|
|--|--|--|--|--|--|
|操作安全|ranger控制hadoop、admin等角色用户权限|是否可控|熊安||架构图|
|操作安全|hadoop两阶段密码|服务器太多，应控制到哪一层级，如何控制|熊安||架构图|
|操作安全|clickhouse default用户命令行分配权限|default密码两阶段配置，通过命令行管理权限|熊安||架构图|
|操作安全|ranger加密配置功能|ranger上配置hdfs、hive数据存储加密方法|熊安||架构图|
|操作安全|hive grant控制spark SQL读写数据权限|通过hive控制权限补充ranger不足，或通过spark插件增加ranger管理spark功能|熊安|不可行，控制不了，需要在数据计算服务中解析SQL，进行权限鉴权|架构图|
|操作安全|hdfs web页面下载功能关闭|验证是否有参数可以控制hdfs web页面下载数据文件功能|熊安|可行|结论|
|存储安全|clickhouse解密数据流程设计|clickhouse 解密数据流程设计，在hive读取时加密，ck解密|熊安|不可行，只能通过新申请cdwck集群来支持aes解密功能|测试样例|
|存储安全|hive、clickhouse AES加解密效率|hive、clickhouseAES加解密效率|李东城|hive测试性能损耗较小，clickhouse性能在测试中|文档|
|操作安全|数据传输、计算过程加密|数据传输计算增加加密配置，根据加密配置进行加解密配置，在数据落地前加密；对外输出或查询时解密;clickhouse获取明文或报表查询时有难度，可能需要封装clickhouse jdbc包|杜延龙|有难度|流程图|
|操作安全|数据计算中数据源连接加密|对数据源连接密码信息进行加密|杜延龙|已和相技沟通获取解决思路|流程图|
|操作安全|数据传输中数据源连接加密|对数据源连接密码信息进行加密|杜延龙|可行|流程图|
|操作安全|datax异常数据落地加密|加密或脱敏输出(针对加密的数据不做额外处理输出即可，输出的就是加密的内容)|杜延龙|可行|流程图|
|网络安全|中台服务器加堡垒机|堡垒机申请中|杜延龙|在申请资源|流程图|
|传输问题|跨集群数据共享传输|目前想到方式计算将数据写入指定集群hdfs|杜延龙|在申请资源|流程图|

测试、生产环境作业id固化如何开发


## 权限现状
|领域|现状|理想状态|备注|
|--|--|--|--|
|部署|生产部署数据应用由应用方自己操作|应由运维，流程待商榷|暂未定|
|部署|中台产品部署由中台人员自己部署|应使用发布系统或运维人员参与|自动部署改造中，预计12月前可上线|
|部署|生产环境OS账号，当前由数据中台创建|应由运维人员维护，流程待商榷|暂未定|
|操作|目前执行和存储用的hadoop账号，还未实现按用户-项目账号区分|应通过用户-项目账号执行和存储|预计12月前可上线|
|开发|目前抽取数据和测试直接连接的生产ps库,数据同样（待与金平确认）|应使用ps测试库，模拟数据|暂未定|
|开发|应用开发和平台研发使用同一测试环境互相干扰|需要单独UAT环境，隔离平台与应用测试环境，减少干扰|本周|
|iSee|IT需持有租户管理员角色，用于权限管理和数据管理；|IT仅持有权限管理角色，将数据管理和权限管理分离；|目标12月底完成|


正在验证跳板机流程，验证通过后可



开发环境ranger地址http://xx.xx.xxx.xx:6080/     账户admin 密码ranger123
             ranger-admin,range-usersync,ranger-hive安装在 xx.xx.xxx.xx /data/ranger，此节点单独起hiveserver2 和metastore服务 
             ranger-hdfs 安装在namenode节点 xx.xx.xxx.xx  /data/ranger   	

高难 技术业务管理拆分：两段密码，三套集群来解决不同安全方案的业务线场景，画出架构图  金平协助整理  保留技术管理域由两段密码控制；hive有ranger管理、clickhouse配置文件+SQL授权语法实现，另外需要考虑项目账号库的授权管理验证

ranger貌似可以控制hadoop账号读取HIVE和HDFS上的数据，admin账号可以通过两段密码限制登录权限
	hive-plugin 和 hdfs-plugin
	ranger可以通过元数据库重置密码
	https://my.oschina.net/u/4016761/blog/4818466
	相应的ranger数据库也需作权限控制

clickhouse可将default用户使用两段密码登录，之后在命令行创建用户分配权限
	https://cloud.tencent.com/developer/article/1630927
	http://clickhouse.com.cn/topic/60ada29158abb810977b6ecd
	https://blog.csdn.net/vkingnew/article/details/107308942
https://blog.csdn.net/qq_35423190/article/details/109726587
https://www.cnblogs.com/zhoujinyi/p/12613026.html

可以使用配置文件限制，限制多用户，以为每个用户单独配置一个xml文件的方式，存放在/etc/clickhouse-server/users.d目录，修改完权限文件之后ClickHouse不需要重启，直接会生效
http://www.weijingbiji.com/1790/
	
20.5版本增加sql-driven,目前版本20.3没有systerm.user等一系列表
https://clickhouse.com/docs/en/whats-new/changelog/2020/#new-feature_7
http://hohode.com/2020/07/29/Clickhouse%E6%96%B0%E7%89%B9%E6%80%A7/
https://www.cnblogs.com/gentlescholar/p/15043329.html
	

ranger的加密是否可应用到hdfs文件和hive查询
	ranger加密可以对某用户定义到库级别，字段级别，行级别的过滤，只对hiveserver2 连接方式有效
	使用hive udf对字段脱敏,hive-sql spark-sql都可以直接使用同一udf
	ranger hdfs插件可限制不同用户对hdfs文件的操作权限 read write execute select
	ranger-hdfs插件授权前提配置，需要配置相应的文件只有文件所有者有权限。
	https://www.ibm.com/docs/en/spectrum-scale-bda?topic=support-using-ranger-secure-hdfs
	https://www.pianshen.com/article/4789983309/
		
	
ranger控制不了spark sql的查询
hive grant、revoke方式管控可以控制到spark sql待验证
	经过测试，可以通过hdfs插件限制表文件对某用户的读写权限,该用户执行hive-sql spark-sql时受hdfs读写权限限制 
	hive grant 开启
	https://www.cnblogs.com/zimo-jing/p/9079538.html
	hive-site.xml增加配置
	

	阿里云方案：基于hdfs权限控制或者基于sql grant 控制
	https://help.aliyun.com/document_detail/62704.html	
		
	hive grant 不能限制 spark-sql 可以限制hiveserve2



hdfs web页面下载数据文件功能关闭？ or 限制
	hadoop配置文件hdfs-site.xml中默认静态页面登录用户为hadoop 修改为无权限的用户可限制从web端查看和下载
	修改core-site.xml
	<property>
        		<name>hadoop.http.staticuser.user</name>
        		<value>hadoop</value>
  	</property>


问题点
hiveserver2连接默认只有用户名校验，没有密码检验。
	自定义密码验证
	https://www.daimafans.com/article/d16588152618614784-p1-o1.html

hive grant漏洞 默认都是超级管理员
https://blog.51cto.com/caiguangguang/1587253
https://www.jianshu.com/p/e5b80c3e7269





## Hive加解密性能测试
### 测试说明

功能：检测UDF对HIVE性能的影响

对象：处理敏感数据的UDF

位置：HIVE \ CLICKHOUSE

### UDF

```
加密:aes_encrypt(input string/binary, key string/binary)
	base64(aes_encrypt('ABC', '1234567890123456')) = 'y6Ss+zCYObpCbgfWfyNWTw=='
解密：aes_decrypt(input binary, key string/binary)
	aes_decrypt(unbase64('y6Ss+zCYObpCbgfWfyNWTw=='), '1234567890123456') = 'ABC'
```

### 处理过程

- [x] 在HDFS创建两张  15  字段的表 t1,t2,t3
- [x] t1->t2  : 分别测试不加密的字段，加密 1、 5、10个字段分别处理后的效果
- [x] t2->t3  : 分别测试不解密的字段，解密 1、 5、10个字段分别处理后的效果
- [x] 使用JAVA模拟生产一天的数据，数据设置3个级别，10万行，百万行，千万行
- [x] 将生成的数据拉取到HDFS
- [x] 通过HIVE将HDFS中的数据加载到 t1
- [x] 通过HIVE的`INSERT INTO xxx select 字段1，字段2... from t1`  并使用加密函数处理数据插入到t2中
- [x] 通过HIVE的`INSERT INTO xxx select 字段1，字段2... from t2` 并使用解密函数处理数据插入到t3中
- [x] 每个值测试5次取平局值
- [ ] 测试group、join的情况



### 测试样例



建表，3张表逻辑一致

```sql
create table if not exists udf_t1(
name string,
phonenumb string,
id string,
mid string,
birthday string,
email string,
create_time string,
randnumb1 string,
randnumb2 string,
randnumb3 string,
randnumb4 string,
randnumb5 string,
randnumb6 string,
randnumb7 string,
randnumb8 string
)
comment 'udf性能测试表'
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
STORED AS textfile
LOCATION '/udf-test/udf-table';
```



#### 场景一： INSERT INTO ... SELECT ...

插入一亿行数据，加密处理10个字段：

```sql
insert overwrite table udf_t2
select
base64(aes_encrypt(name,'1234567890123456')) name,
base64(aes_encrypt(phonenumb,'1234567890123456')) phonenumb ,
base64(aes_encrypt(id,'1234567890123456')) id ,
base64(aes_encrypt(mid,'1234567890123456')) mid ,
base64(aes_encrypt(birthday,'1234567890123456')) birthday ,
base64(aes_encrypt(email,'1234567890123456')) email ,
base64(aes_encrypt(create_time,'1234567890123456')) create_time,
base64(aes_encrypt(randnumb1,'1234567890123456')) randnumb1 ,
base64(aes_encrypt(randnumb2,'1234567890123456')) randnumb2 ,
base64(aes_encrypt(randnumb3,'1234567890123456')) randnumb3 ,
randnumb4 ,
randnumb5 ,
randnumb6 ,
randnumb7 ,
randnumb8
from udf_t1;
```

测试结果：

```
[2021-09-23 21:38:37] completed in 1 m 44 s 433 ms
```



插入一亿行数据，解密处理10个字段：

```sql
insert overwrite table udf_t3
select
aes_decrypt(unbase64(name), '1234567890123456') name,
aes_decrypt(unbase64(phonenumb), '1234567890123456') phonenumb ,
aes_decrypt(unbase64(id), '1234567890123456') id ,
aes_decrypt(unbase64(mid), '1234567890123456') mid ,
aes_decrypt(unbase64(birthday), '1234567890123456') birthday ,
aes_decrypt(unbase64(email), '1234567890123456') email ,
aes_decrypt(unbase64(create_time), '1234567890123456') create_time,
aes_decrypt(unbase64(randnumb1), '1234567890123456') randnumb1 ,
aes_decrypt(unbase64(randnumb2), '1234567890123456') randnumb2 ,
aes_decrypt(unbase64(randnumb3), '1234567890123456') randnumb3 ,
randnumb4 ,
randnumb5 ,
randnumb6 ,
randnumb7 ,
randnumb8
from udf_t2;
```

测试结果：

```
[2021-09-23 21:38:37] completed in  1 m 50 s 658 ms
```

##### 结果统计

加密

|             | 不+udf      | 1个字段+udf    | 5个字段+udf     | 10个字段+udf    |
| ----------- | ----------- | -------------- | --------------- | --------------- |
| 1千万行数据 | 18 s 533 ms | 20 s 362 ms    | 21 s 322        | 25 s 84 ms      |
| 5千万行数据 | 32 s 352 ms | 35 s 869 ms    | 42 s 511 ms     | 51 s 355 ms     |
| 一亿行数据  | 50 s 26 ms  | 1 m 2 s 448 ms | 1 m 10 s 126 ms | 1 m 53 s 649 ms |



解密

|             | 不+udf      | 1个字段+udf | 5个字段+udf    | 10个字段+udf    |
| ----------- | ----------- | ----------- | -------------- | --------------- |
| 1千万行数据 | 18 s 516 ms | 19 s 24 ms  | 21 s 630 ms    | 24 s 560 ms     |
| 5千万行数据 | 32 s 513 ms | 35 s 516 ms | 42 s 334 ms    | 1 m 1 s 868 ms  |
| 一亿行数据  | 50 s 34 ms  | 55 s 122 ms | 1 m 9 s 584 ms | 1 m 51 s 214 ms |



#### 场景二：SELECT

查询一亿行数据，加密处理10个字段：

```sql
select
base64(aes_encrypt(name,'1234567890123456')) name,
base64(aes_encrypt(phonenumb,'1234567890123456')) phonenumb ,
base64(aes_encrypt(id,'1234567890123456')) id ,
base64(aes_encrypt(mid,'1234567890123456')) mid ,
base64(aes_encrypt(birthday,'1234567890123456')) birthday ,
base64(aes_encrypt(email,'1234567890123456')) email ,
base64(aes_encrypt(create_time,'1234567890123456')) create_time,
base64(aes_encrypt(randnumb1,'1234567890123456')) randnumb1 ,
base64(aes_encrypt(randnumb2,'1234567890123456')) randnumb2 ,
base64(aes_encrypt(randnumb3,'1234567890123456')) randnumb3 ,
randnumb4 ,
randnumb5 ,
randnumb6 ,
randnumb7 ,
randnumb8
from udf_t1;
```

测试结果：

```
[2021-09-24 10:59:20] 500 rows retrieved starting from 1 in 1 m 56 s 245 ms (execution: 1 m 55 s 80 ms, fetching: 445 ms)
```



查询一亿行数据，解密处理10个字段：

```sql
select
aes_decrypt(unbase64(name), '1234567890123456') name,
aes_decrypt(unbase64(phonenumb), '1234567890123456') phonenumb ,
aes_decrypt(unbase64(id), '1234567890123456') id ,
aes_decrypt(unbase64(mid), '1234567890123456') mid ,
aes_decrypt(unbase64(birthday), '1234567890123456') birthday ,
aes_decrypt(unbase64(email), '1234567890123456') email ,
aes_decrypt(unbase64(create_time), '1234567890123456') create_time,
aes_decrypt(unbase64(randnumb1), '1234567890123456') randnumb1 ,
aes_decrypt(unbase64(randnumb2), '1234567890123456') randnumb2 ,
aes_decrypt(unbase64(randnumb3), '1234567890123456') randnumb3 ,
randnumb4 ,
randnumb5 ,
randnumb6 ,
randnumb7 ,
randnumb8
from udf_t2;
```

测试结果：

```
[2021-09-24 12:17:50] 500 rows retrieved starting from 1 in 2 m 10 s 527 ms (execution: 2 m 10 s 02 ms, fetching: 507 ms)
```




##### 结果统计

加密

|             | 不+udf | 1个字段+udf | 5个字段+udf     | 10个字段+udf    |
| ----------- | ------ | ----------- | --------------- | --------------- |
| 1千万行数据 | 441 ms | 16 s 27 ms  | 18 s 36 ms      | 22 s 43 ms      |
| 5千万行数据 | 573 ms | 36 s 746 ms | 40 s 534 ms     | 55 s 868 ms     |
| 一亿行数据  | 744 ms | 59 s 476 ms | 1 m 14 s 834 ms | 1 m 53 s 831 ms |

解密

|             | 不+udf | 1个字段+udf     | 5个字段+udf     | 10个字段+udf   |
| ----------- | ------ | --------------- | --------------- | -------------- |
| 1千万行数据 | 418 ms | 23 s 88 ms      | 25 s 793 ms     | 27 s 420 ms    |
| 5千万行数据 | 435 ms | 37 s 87 ms      | 46 s 771 ms     | 1 m 8 s 577 ms |
| 一亿行数据  | 533 ms | 2 m 17 s 901 ms | 2 m 18 s 916 ms | 2 m 8 s 153 ms |

## Clickhouse 解密性能

待补充

